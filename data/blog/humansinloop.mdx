---
title: 'Humans in the Loop'
date: '2025-05-22'
lastmod: '2025-05-22'
tags: ['ai', 'technology', 'workforce', 'future']
draft: false
summary: 'A reflection on the rapid rise of AI automation, its implications on traditional companies, and the evolving role of humans in the future workforce.'
images: ['/static/images/ai-automation-workforce.jpg']
---
Consider people working in one vertical of a huge software company, responsible for a chunk of its operations—be it HR for hiring, development of features if they're engineers, digital marketing, or sales, etc. And some guy appears in a YouTube ad promoting the trope that AI won't replace them, but someone using AI surely will.

Now, they are left wondering, that despite the usefulness of chatgpt that they themselves have found in a limited portion of their work, how the hell can it even understand the entirety of the clusterfuck they are doing, let alone replace them. Because they realize that there is some context information about the company operations, that they alone know about. Like the weird preference of font style that his client might have communicated during a presentation, but is not documented anywhere, or a table in a database which has got their column names mixed up, or the credential for semrush saved in some google doc.

Sure enough, once in a while the company deprioritises the project and renders their work obsolete. But this is part of a normal cycle. It is very difficult to imagine that this displacement can happen on such a large scale, that huge chunks of work across departments is being done using automation brought about by AI.

It's very easy to buy into the optimistic view that AI is generally too unstable to adapt to changing real-world information and too unreliable to consistently make intelligent decisions given environmental complexity and dynamism.

Instead, one should generally be wary of the things where the top scientific and technological minds of the world dedicate their time to, and top venture capitalists are investing their money in. These projects have a very high probability of success.

And we are not talking about a distant future; automations spelling doomsday for white-collar workers are already everyday events. Large scale layoffs at big tech have become quite common. The earlier question about whether the siloed and undefined nature of company-related context poses an obstacle to the widespread automation driven by AI still remains. The answer in my mind is, these huge companies with siloed data are like dinosaurs which can't adapt to the efficiency devouring AI age. They would need a complete overhaul to survive. Imagine a future company operating in the same domain generating the same revenue with just 10%, or in some cases, merely 1% of the current employee count. Such companies would be extremely difficult to compete with long-term, even if these dinosaur companies currently have a significant customer base.

The core of today's AI applications is a base transformer model, trained on vast digital and digitized datasets, which possesses extensive world knowledge and can communicate in natural language. It also has reasoning capacities to understand what instruction it has been given.

Now imagine you give this behemoth 'brain' multiple arms—tools enabling it to break tasks into smaller pieces, navigate the internet as humans do, execute code in any programming language, and read unstructured documents, among other capabilities. And guess what—if the need arises, even humans can be utilized as one of its tools. And if it doesn't find satisfactory results, it can keep reusing its arms to get the desired result.

It turns out that almost any larger project can be broken down into smaller tasks. And given access to these tools, and an ability to reflect upon and act on the result of these tools, it becomes a really powerful system. They are called agents, autonomous entities capable of performing specific tasks through interactions with language models and other components.

And if you have many such agents working in tandem—a workforce—they can ideally perform very complex tasks.

Long story short, as Bret Taylor of CTO at Meta at 29 and Google map creator fame says, the face of every company has shifted from websites, to smartphone apps in the past. In the next 5 years or even less, they are going to have AI agents as their new face. We can talk sometime later about how this transition is going to look like. But one thing is clear: traditional companies, whose products are merely wrappers around databases, will go through a phase of radical atrophy. And new products are emerging that provide natural language interfaces to data as well as the UI.

Now how would humans fit in this new reality? The Automation Paradox says that increasing automation in a system reduces the operator’s active involvement, but increases their responsibility when something goes wrong. Imagine an assembly line producing dozens of cars every hour, and a single error in carburetor adjustment creeps in. If this problem goes unnoticed for a day, then you have produced 250 faulty cars. That is the cost of lack of human oversight. Thus, you will need humans to supervise the system, regardless of how advanced your evaluations and error detection become.

Also, as any business grows and product matures, there is an at least proportional growth in the number of rabbit holes and edge cases. What it means basically is that your workflow would need to handle those edge cases, which you did not envisage prior to framing the abstractions and assumptions of the business. A problem which however smart your agent is, would need some external help and a human understanding and awareness to handle. You would add more abstraction, bring in more complexity to automate it, but it might give rise to further more complex edge cases. This explosion of complexity is what I think would need more smart people to handle.

Interested readers might draw a parallel of the above argument with Godel's incompleteness theorem. Although I lack the expertise to rigorously establish this correspondence, I would gladly entertain further discussion about it.

To sum up, industry might need fewer humans in the short run, as is evident by the current lack of entry level positions and frequent layoffs in big tech. But gradually the demand will catch-up for good problem solvers.